{
  "name": "uubench",
  "version": "0.0.1",
  "description": "A tiny asynchronous JavaScript benchmarking library",
  "author": {
    "name": "Aleksander Williams"
  },
  "contributors": [],
  "url": "http://github.com/akdubya/uubench",
  "keywords": [
    "benchmarking"
  ],
  "main": "uubench",
  "scripts": {
    "test": "make test"
  },
  "readme": "uubench\n=======\n\n> A tiny asynchronous JavaScript benchmarking library\n\nuubench provides a simple harness for measuring the execution time of JavaScript code. Design your experiments, analyze the numbers and present the data as you see fit.\n\nFeatures:\n\n* small (~100 LOC)\n* asynchronous, evented operation\n* fixed or adaptive test cycles\n* no DOM-related cruft\n\nSynopsis\n--------\n\nSet up a benchmark suite:\n\n    var suite = new uubench.Suite({\n      start: function() {\n        console.log(\"starting...\");\n      },\n      result: function(name, stats) {\n        console.log(name + \": \" + stats.iterations/stats.elapsed);\n      },\n      done: function() {\n        console.log(\"finished\");\n      }\n    });\n\nAdd some benchmarks:\n\n    suite.bench(\"async\", function(next) {\n      myAsyncFunc(function() {\n        next();\n      });\n    });\n\n    suite.bench(\"sync\", function(next) {\n      mySyncFunc();\n      next();\n    });\n\nGo man go!\n\n    suite.run();\n\nInstallation\n------------\n\nVia npm:\n\n    $ npm install uubench\n\nIn Node:\n\n    var uubench = require('uubench');\n\nIn the browser:\n\n    <script src=\"uubench.js\"></script>\n\nGuide\n-----\n\nBy design, uubench doesn't come with extras. Instead, you use the low-level API to build your own unique benchmark suites.\n\n### Defaults\n\nuubench ships with the following defaults that apply to every test suite:\n\n    uubench.defaults = {\n      type:       \"adaptive\", // adaptive or fixed\n      iterations: 10,         // starting iterations\n      min:        100,        // minimum run time (ms) - adaptive only\n      delay:      100         // delay between tests (ms)\n    }\n\nYou may override these globally or per-suite. Read on to find out what each option does.\n\n### Fixed test cycles\n\nBy default uubench uses adaptive test cycles to allow reasonable execution time across different environments. To use fixed cycles instead, set the `type` to \"fixed\":\n\n    var suite = new uubench.Suite({\n      type: \"fixed\",\n      iterations: 1000, // run each benchmark exactly 1000 times\n      ...\n    });\n\n### Setting the minimum runtime\n\nuubench defaults to a minimum runtime of 100ms in adaptive mode. To adjust this runtime:\n\n    var suite = new uubench.Suite({\n      min: 1000, // each benchmark should run for at least 1000ms\n      ...\n    });\n\n### Starting iterations\n\nIn adaptive mode it is sometimes useful to bump up the starting iterations to reach the minimum runtime faster:\n\n    var suite = new uubench.Suite({\n      iterations: 1000, // run each benchmark a minimum of 1000 times\n      ...\n    });\n\n### Setting the benchmark delay\n\nuubench imposes a 100ms delay between benchmarks to give any UI elements that might be present time to update. This delay can be tweaked:\n\n    var suite = new uubench.Suite({\n      delay: 500, // 500ms delay between benchmarks\n      ...\n    });\n\n### Disabling auto-looping\n\nTo manually loop within a given benchmark, add a second argument to the benchmark's argument list. uubench will then automatically disable auto-looping:\n\n    suite.bench(\"foo\", function(next, count) {\n      while (count--) {\n        ...\n      }\n      next();\n    });\n\n### Multiple runs\n\nTo collect benchmark data over multiple runs, simply rerun the suite on completion:\n\n    var suite = new uubench.Suite({\n      ...\n      done: function() {\n        if (--runCounter) {\n          console.log(\"I'm finished!\");\n        } else {\n          suite.run();\n        }\n      }\n    });\n\nBeware of relying on multiple in-process runs to establish statistical relevance. Better data can be obtained by completely re-running your test scripts.\n\n### Stats\n\nRather than imposing a limited statistical model on benchmark data, uubench gives you the raw numbers. If you want to go nuts with the math have a look at [this gist](http://gist.github.com/642690).\n\n### Loop calibration\n\nIn most cases auto looping doesn't add enough overhead to benchmark times to be worth worrying about, but extremely fast benchmarks can suffer. Add a calibration test if you want to correct for this overhead:\n\n    suite.bench(\"calibrate\", function(next) {\n      next();\n    });\n\nYou can then subtract the elapsed time of the \"calibrate\" test from other tests in the suite.\n\nExamples\n--------\n\n* Dust browser benchmarks: <http://akdubya.github.com/dustjs/benchmark/index.html>\n* Dust node benchmarks: <http://github.com/akdubya/dustjs/blob/master/benchmark/server.js>\n\nAbout\n-----\n\nuubench was inspired by the venerable [jslitmus](http://github.com/broofa/jslitmus)",
  "readmeFilename": "README.md",
  "_id": "uubench@0.0.1",
  "dist": {
    "shasum": "b6ec131835aa23e9e905518273585adc54a8a790"
  },
  "_from": "uubench@*",
  "_resolved": "https://registry.npmjs.org/uubench/-/uubench-0.0.1.tgz"
}
